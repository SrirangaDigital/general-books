<?xml version="1.0" encoding="utf-8"?> 
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en" xmlns:epub="http://www.idpf.org/2007/ops"> 
<head>        
	<title>ON THE PROBABILITY DISTRIBUTIONS INDUCED BY INTEGER SEQUENCES GENERATED BY RECURRENCE RELATIONS WITH POSITIVE INTEGER COEFFICIENTS</title> 
	<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1" /> 
	<script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});</script>  
	<script type="text/javascript" async src="https://srirangadigital.com/accs-html/js/MathJax-master/MathJax.js?config=TeX-MML-AM_CHTML"></script>
	<script type="text/x-mathjax-config">
		MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
		MathJax.Hub.Config({
		  TeX: {
			Macros: {
				displayfrac: ["\\frac{\\displaystyle \#1}{\\displaystyle \#2}",2],
				fq: "\\mbox{$\\mathbb{F}_q$}",
				calc: "\\mbox{$\\mathcal{C}$}",
				calcperp: "\\mbox{$\\mathcal{C}^{\\perp}$}"
			}
		  }
		});
		MathJax.Hub.Config({
		  TeX: { equationNumbers: { autoNumber: "AMS" } }
		});		
	</script>
	<script type="text/javascript" async src="js/MathJax-master/MathJax.js?config=TeX-MML-AM_CHTML"></script>
	<link rel="stylesheet" type="text/css" href="css/style.css"/> 
	<link rel="stylesheet" type="text/css" href="overrides/style.css" />
</head>
<body class="maintext">
<h1 class="heading" id="id-art1-001">ON THE PROBABILITY DISTRIBUTIONS INDUCED BY INTEGER SEQUENCES GENERATED BY RECURRENCE RELATIONS WITH POSITIVE INTEGER COEFFICIENTS</h1>
<p class="authors">Arulalan Rajan, R. Vittal Rao, H. S. Jamadagni<br /><small class="affiliation">Department of Electronic Systems Engineering, Indian Institute of Science, Bengaluru</small></p>
<p class="authors">Ashok Rao<br /><small class="affiliation">Consultant, 165, 11th main, Saraswathipuram, Mysuru</small></p>

<p>The classical Fibonacci sequence is known to exhibit many fascinating properties. In this paper, we explore the Fibonacci sequence and integer sequences generated by second order linear recurrence relations with positive integer coeffcients from the point of view of probability distributions that they induce. We obtain the generalizations of some of the known limiting properties of these probability distributions and present certain optimal properties of the classical Fibonacci sequence in this context. In addition, we also look at the self linear convolution of linear recurrence relations with positive integer coefficients. Analysis of self linear convolution is focused towards locating the maximum in the resulting sequence. This analysis, also highlights the in uence that the largest positive real root, of the ``characteristic equation" of the linear recurrence relations with positive integer coefficients, has on the location of the maximum. In particular, when the largest positive real root is 2, the location of the maximum is shown to depend on the sequence length being odd or even.</p>
<p><strong>Key words.</strong> Fibonacci sequence, recurrence relations, probability distribution, limiting properties, linear convolution</p>
<p><strong>AMS subject classifications.</strong> 11B37, 11B39, 60C05, 60C09, 60F99</p>

<h2 id="chap1-sec-1"><span class="num">1</span>&#x00A0;&#x00A0; Introduction</h2>

<p>Starting with any sequence $\{f[n]\}_{n\in \mathbb N}$ of positive real numbers, we can generate a probability distribution on $\{1; 2; : : : ;N\}$ for every $N \in \mathbb N$ as follows: Let $X$ be a random variable taking values $1; 2; : : : ;N$ such that</p>

$$
P(X=n) = \displaystyle{\frac{f[n]}{\displaystyle{\sum_{k=1}^N}f[k]}}
$$

In particular, if $f[n]$ are all positive integers, then we can generate such probability distributions using only integers. In a recent work, Neal \cite{art1-key01} has investigated such probability distributions arising out of the Fibonacci sequence and obtained some limiting properties of these distributions as $N \rightarrow \infty$.

While exploring integer sequences from the point of view of generating window functions in the context of designing digital filters for signal processing applications \cite{art1-key02}, we found some generalizations of Neal's limiting properties for a class of integer sequences and an optimal property of the Fibonacci sequence in this class. In this paper, we present these results.

<h2 id="chap1-sec-2"><span class="num">2</span>&#x00A0;&#x00A0; Probability Distributions Induced by Fibonacci Sequence</h2>

<p>The classical Fibonacci sequence \cite{art1-key03}, \cite{art1-key04}, is the positive integer sequence $f[n]$ defined by the second order recurrence relation</p>

 <p>\begin{equation}
  f[n] = f[n-1] + f[n-2]\tag{2.1}\label{2.1}
    \end{equation}</p>
    
<p>with initial conditions $f[1] = 1$, $f[2] = 1$.</p>

<p>$$
\lim_{k \rightarrow \infty} \frac{f[k+1]}{f[k]} = \varphi = \displaystyle{\frac{1 + \sqrt5}{2}}\tag{2.2}\label{2.2}
$$
</p>

For any positive integer $N$, consider the Fibonacci sequence, $f[1], f[2], \ldots, f[N]$, of length $N$. Using the Fibonacci sequence, we can define a discrete probability distribution as follows. We define the probability mass function as\footnote{${\bar{(.)}}$: associated with increasing sequence}

<p>
$$
p_{_{\bar{N}}}[1], p_{_{\bar{N}}}[2], \ldots, p_{_{\bar{N}}}[N]
$$</p>


<p>\begin{equation}
 p_{_{\bar{N}}}(n) = \frac{f[n]}{\displaystyle{\sum_{k =1}^N f[k]}} \hspace{0.3in} \forall n = 1, 2, \ldots, N \tag{2.3}\label{2.3}
 \end{equation}</p>


<p>Let $\bar{X}$ be a random variable in $\{1,2, \ldots, N\}$ such that</p>

 
<p>\begin{equation}
P(\bar{X} = n) = p_{_{\bar{N}}}(n); \hspace{0.3in} 1 \leq n\leq N.\tag{2.4}\label{2.4}
\end{equation}</p>
 
<p>In his work, Neal \cite{art1-key01} showed that, $E(\bar{X})$, the mean or expectation of $\bar{X}$, grows linearly as $N$ increases and hence </p>
<p>\begin{equation}
\lim_{N\rightarrow \infty} E(\bar{X}) = \infty\tag{2.5}\label{2.5}
\end{equation} </p>


<p>Similarly, let $\underline{X}$ be a random variable in $\{1,2, \ldots, N\}$, where the probabilities, $p_{_{\underline{N}}}[n]$, correspond to the Fibonacci sequence, of length $N$, in the decreasing order\footnote{${(\underline{.})}$ : associated with decreasing sequence}. We define the probability mass function,</p>
<p>\begin{equation}
P(\underline{X} = n) = \frac{f[N+1-n]}{\displaystyle{\sum_{k =1}^N f[k]}} = p_{_{\underline{N}}}(n) \hspace{0.2in} ; \hspace{0.2in} 1 \leq n\leq N.\tag{2.6}\label{2.6}
 \end{equation}</p>

<p>For such a random variable, $\underline{X}$, Neal \cite{art1-key01} observed the following limiting properties:</p>
<p>\begin{equation}
\lim_{N\rightarrow \infty} E(\underline{X}) = \varphi + 1\tag{2.7}\label{2.7}
\end{equation}</p>
<p>\begin{equation}
\lim_{N\rightarrow \infty} Var(\underline{X}) = 2\varphi + 1\tag{2.8}\label{2.8}
\end{equation}</p>
<p>where $E(\underline{X})$ denotes the mean or expectation of $\underline{X}$ and $Var(\underline{X})$ denotes the variance of $\underline{X}$.</p>

<p>The aim of this paper, as mentioned earlier, is to show that such limiting properties are characteristic for integer sequences defined by linear recurrence relations , of any order, with positive integer coefficients. For the sake of simplicity, we shall first discuss the second order recurrence relation.</p> 


<h2 id="chap1-sec-3"><span class="num">3</span>&#x00A0;&#x00A0; Second Order Recurrence Relations</h2>

<p>Let $a$, $b$ be any two positive integers and consider the integer sequence defined by the second order recurrence relation</p>
<p>\begin{equation}
f[n] = a f[n-1] + b f[n-2] \hspace{0.1in}  {\rm where} \hspace{0.1in}  f[1] = 1; f[2]= 1;\tag{3.1}\label{3.1}
\end{equation}</p>
 
<p>The characteristic equation of this recurrence relation is given by</p>
<p>\begin{equation}
r^2 - ar - b = 0.\tag{3.2}\label{3.2}
\end{equation}</p>
<p>It is well known that the solution to this Eq.~\eqref{3.2} is given by</p>
<p>\begin{equation*}
f[n] =  C[R(a,b)^n - R_s(a,b)^n]
\end{equation*}</p>
<p>where, </p>
<p>\begin{equation*}
R(a,b) = \displaystyle{\frac{a +\sqrt{a^2 + 4b}}{2}}
\end{equation*}</p>
<p>is the positive real root. The other root of the equation is </p>
<p>\begin{equation*}
R_s = - \frac{b}{R(a,b)}
\end{equation*}</p>
<p>and</p>
<p>\begin{equation*}
C = \displaystyle{\frac{1}{\sqrt{a^2 + 4b}}}
\end{equation*}</p>
<p>We note that,</p>

<p>\begin{align}
R(a,b) &\geq \varphi \hspace{0.1in} {\rm for all positive integers} \hspace{0.1in} a, b \tag{3.3}\label{3.3}\\
R(a,b) &= \varphi   \hspace{0.1in}{\rm when}\hspace{0.1in} a = b = 1\tag{3.4}\label{3.4}\\
       & \quad\quad {(\rm classical Fibonacci sequence)}\nonumber
\end{align}</p>

<p>We further observe that the ratio of successive terms of this sequence converges to $R(a,b)$, i.e.,</p>

<p>\begin{equation}
\lim_{k \rightarrow \infty} \frac{f[k+1]}{f[k]} = R(a,b)\tag{3.5}\label{3.5}
\end{equation}</p>
<p>As in section~\ref{section-2}, for any positive integer $N$, consider the above sequence, of length $N$, i.e.,</p>
<p>$$f[1],f[2], \ldots, f[N]$$</p>

<p>and define probability mass functions,</p>
<p>$$
p_{_{\bar{N}}}(n)[1],p_{_{\bar{N}}}(n)[2], \ldots, p_{_{\bar{N}}}(n)[N]
$$</p>
<p>as</p>
<p>\begin{equation}
 p_{_{\bar{N}}}(n) = \frac{f[n]}{\displaystyle{\sum_{k =1}^N f[k]}} \hspace{0.3in} \forall n = 1, 2, \ldots, N\tag{3.6}\label{3.6}
\end{equation}</p>
<p>Consider a random integer, $\bar{X}$, in $\{1,2, \ldots, N\}$, such that</p>
<p>\begin{equation}
P(\bar{X} = n) = p_{_{\bar{N}}}(n)\tag{3.7}\label{3.7}
\end{equation} </p>
<p>Similarly let $\underline{X}$ be a random variable in $\{1,2, \ldots, N\}$, (with probabilities corresponding to the decreasing sequence) such that, </p>
<p>\begin{equation}
P(\underline{X} = n) = \frac{f[N+1-n]}{\displaystyle{\sum_{k =1}^N f[k]}} = p_{_{\underline{N}}}(n) \hspace{0.3in} \forall n = 1, 2, \ldots, N\tag{3.8}\label{3.8}
\end{equation} </p>
 <p>In the rest of the paper, for short, we shall denote $R(a,b)$ by $R$ and $R_S(a,b)$ by $R_S$.</p>
 
  
<h2 id="chap1-sec-4"><span class="num">4</span>&#x00A0;&#x00A0; The Main Theorems on the Limiting Properties</h2>

<p>We prove the following limiting properties.</p>

<p>Analogous to eq.~(\ref{eq-2.5}), we have,</p>

<p id="theorem-4.1"><strong>Theorem 1.</strong></p><!-- \label{thm-4.1}-->
<p>\begin{equation*}
\lim_{N \rightarrow \infty} E(\bar{X}) = \infty
\end{equation*}</p>

<p>Even though $E(\bar{X})$ grows as $N$ increases, its variance still converges. In fact, we have,</p>
<p id="theorem-4.2"><strong>Theorem 2.</strong></p><!-- \label{thm-4.2}--> 
<p>\begin{equation*}
\lim_{N \rightarrow \infty} Var(\bar{X}) = \frac{R}{(R-1)^2}
\end{equation*}</p>

<p>In the case of $\underline{X} $, both $E(\underline{X})$ and $Var(\underline{X})$ converge as $N \rightarrow \infty$ and the limit of $Var(\underline{X})$ is the same as that of $Var(\bar{X})$. We have, analogous to eq.~(\ref{eq-2.7}) and eq.~(\ref{eq-2.8}), the following limits.</p>
<p id="theorem-4.3"><strong>Theorem 3.</strong></p><!-- \label{thm-4.3}--> 
<p>\begin{equation}\nonumber
\lim_{N \rightarrow \infty} E(\underline{X}) = \frac{R}{(R-1)}
\end{equation}</p>
<p id="theorem-4.4"><strong>Theorem 4.</strong></p><!-- \label{thm-4.4}--> 
 <p>\begin{equation}\nonumber
\lim_{N \rightarrow \infty} Var(\underline{X}) = \frac{R}{(R-1)^2}
\end{equation}</p>
  <p>We, then, easily observe using these properties that when $a = b = 1$, the limits of Theorem.~(\ref{thm-4.1}), Theorem.~(\ref{thm-4.2}) and Theorem.~(\ref{thm-4.3}) reduce to the limits, eq.~(\ref{eq-2.5}), eq.~(\ref{eq-2.7}), eq.~(\ref{eq-2.8}), obtained for the Fibonacci sequence, by Neal \cite{art1-key01}, described in section~\ref{section-2}. Using eq.~(\ref{eq-3.3}) and eq.~(\ref{eq-3.4}), we can prove the following optimality properties of the Fibonacci sequence:</p>
<p id="theorem-4.5"><strong>Theorem 5.</strong></p><!-- \label{thm-4.5}--> 
<p>\begin{align*}
\max{\left(\lim_{N\rightarrow \infty} E(\underline{X}): a, b \in \mathbb N \right)} &= \lim_{N \rightarrow \infty}\left(E(\underline{X}):a=b=1\right)\\
 &= \varphi + 1
\end{align*}</p>
<p id="theorem-4.6"><strong>Theorem 6.</strong></p><!-- \label{thm-4.6}--> 
<p>\begin{align*}
\max{\left (\lim_{N\rightarrow \infty}Var(\bar{X}): a,b \in \mathbb N\right)} &=\max{\left(\lim_{N\rightarrow \infty}Var(\underline{X}): a,b \in \mathbb N\right)}\\
&= \lim_{N \rightarrow \infty}\left(Var(\underline{X}):a=b=1\right)= 2\varphi + 1
\end{align*}</p>

<p>We now proceed to prove these theorems.</p>

<h2 id="chap1-sec-5"><span class="num">5</span>&#x00A0;Some Notations Used in the Following Sections</h2>

<p>In order to prove the aforesaid theorems, we make use of certain finite sums, presented in \textbf{Appendix.~\ref{section-app-a}} and \textbf{Appendix.~\ref{section-app-b}}. We list here, some of the notations used in the subsequent sections.</p>

<table style="width:70%" id="chap1-table-4">
<tr>
<th>Increasing sequence</th>
<th>Decreasing Sequence</th>
</tr>
<tr>
<td style="text-align:center">$\bar{S} = \displaystyle{\sum_{n=1}^{N}}f[n]$</td>
<td style="text-align:center">$\underline{S} = \displaystyle{\sum_{n=1}^{N}}f[N+1-n]$</td>
</tr>
<tr>
<td style="text-align:center">$\bar{S}_1 = \displaystyle{\sum_{n=1}^{N}}n f[n]$</td>
<td style="text-align:center">$\underline{S}_1 = \displaystyle{\sum_{n=1}^{N}}n f[N+1-n]$</td>
</tr>
<tr>
<td style="text-align:center">$\bar{S}_2 = \displaystyle{\sum_{n=1}^{N}}n^2 f[n]$</td>
<td style="text-align:center">$\underline{S}_2 = \displaystyle{\sum_{n=1}^{N}}n^2 f[N+1-n]$</td>
</tr>
</table>

<h2 id="chap1-sec-6"><span class="num">6</span>&#x00A0; Proofs of Theorems Related to Distributions Induced by Increasing Sequences</h2>

<p>We look at the mean and variance of the random variable $\bar{X}$, defined as in section \ref{section-2}.</p>

<p>THEOREM {\ref{thm-4.1}}:}</p>
<p>\begin{equation*}
\displaystyle{\lim_{N \rightarrow \infty}} E(\bar{X}) = \infty  
 \end{equation*}</p>

<p><em>Proof~:</em></p>

<p>We have,</p>
<p>\begin{equation}
E(\bar{X}) = \frac{\bar{S}_1}{\bar{S}}\tag{6.1}\label{6.1}
\end{equation}</p>
<p>Using eq.~(\ref{B.8}) and eq.~(\ref{B.6}), we get</p>
<p>\begin{align}
E(\bar{X})&\sim \frac{(NR^{N+2}-(N+1)R^{N+1}+R)(R-1)}{(R-1)^2 R^{N+1}}\nonumber\\
&\sim \frac{NR-N-1}{R-1}\nonumber\\
\Rightarrow E(\bar{X}) &\sim N - \frac{1}{R-1}\tag{6.2}\label{6.2}\\
\nonumber E(\bar{X}) &\sim \mathcal{O}(N)
\end{align}\hfill{$\square$\\}</p>

<p>Theorem~\ref{thm-4.1}, now follows from eq.~(\ref{eq-6.2}).</p>

<p>We also observe the following:</p> 

 <p>If we now define $\bar Y$ = $(N+1)- \bar{X}$, so that $\bar{Y}$ is also a random variable taking value 1, 2, 3, $\ldots$, $N$ and $\bar{X}$ has been in a sense centralized, then by eq.~(\ref{eq-6.2}),</p>
 <p>\begin{equation*}
 E(\bar{Y}) \sim 1 + \frac{1}{R-1} = \frac{R}{R-1}
 \end{equation*}</p>
<p>Hence </p>
<p>\begin{equation*}
\displaystyle{\lim_{N \rightarrow \infty}} E(\bar{Y}) = \frac{R}{R-1} 
\end{equation*}</p>
<p>This $\bar{Y}$ corresponds to $\underline{X}$, which we describe in sec.~\ref{section-7}.</p>
<p>THEOREM~{\ref{thm-4.2}}:}</p>
<p>\begin{eqnarray*}
\lim_{N \rightarrow \infty} Var(\bar{X}) = \frac{R}{(R -1)^2}
\end{eqnarray*}</p>

<p><em>Proof~:</em></p>

<p>We have,</p>
<p>\begin{equation}
E(\bar{X}^2) = \frac{\bar{S}_2}{\bar{S}}\tag{6.3}\label{6.3}
\end{equation}</p>

<p>Using eq.(\ref{B.10}) and eq.(\ref{B.6}), we get</p>
<p>\begin{equation}
E(\bar{X}^2) \sim \frac{N^2(R-1)^2 - 2N(R-1) + R+1}{(R-1)^2}\tag{6.4}\label{6.4}
\end{equation}</p>

<p>Using eq.~(\ref{eq-6.2}) and eq.~(\ref{eq-6.4}), we get</p>

<p>\begin{align*}
Var(\bar{X})&= E(\bar{X}^2)-E(\bar{X})^2\nonumber \\
&\sim \frac{N^2(R-1)^2 - 2N(R-1) + R+1}{(R-1)^2}-\left(N - \frac{1}{R-1}\right)^2\nonumber\\
\Rightarrow \lim_{N \rightarrow \infty}Var(\bar{X})& =  \frac{(R+1)-1}{(R-1)^2}\nonumber
\end{align*}</p>

<p>Thus, we get the limit of the variance as,</p>
<p>\begin{equation}
\lim_{N \rightarrow \infty}Var(\bar{X}) = \frac{R}{(R-1)^2}\tag{6.5}\label{6.5}
\end{equation}</p>


$$\hfill{$\square$\\}$$


<p>It is interesting to note from eq.~(\ref{eq-6.2}) and eq.~(\ref{eq-6.5}) that, even though the mean increases linearly as the length of the sequence, the variance converges, to a function of $R$.</p>

<h2 id="chap1-sec-7"><span class="num">7</span>&#x00A0; Proofs of Theorems Related to Distributions Induced by Decreasing Sequences</h2>

<p>In this section, we look at the probability distribution generated by reversing the sequence values. We recall that the probability of the random variable $\underline{X}$ taking a value $n$ was defined as,</p>
<p>\begin{equation}
P(\underline{X} = n) =\frac{f[N+1-n]}{\displaystyle{\sum_{k=1}^{N}f[N+1-k]}} = p_{_{\underline{N}}}(n)\tag{7.1}\label{7.1}
\end{equation}</p>

<p>THEOREM~{\ref{thm-4.3}}:}</p>
<p>\begin{eqnarray*}
\displaystyle{\lim_{N \rightarrow \infty}}E(\underline{X}) = 1 + \displaystyle{\frac{1}{R-1}} =  \displaystyle{\frac{R}{R-1}}
\end{eqnarray*}</p>

<p><em>Proof~:</em></p>

<p>We have,</p>
<p>\begin{equation}
E(\underline{X}) = \frac{\underline{S}_1}{\underline{S}}\tag{7.2}\label{7.2}
\end{equation}</p>
<p>From eq.~(\ref{B.13}), we get</p>
<p>\begin{align}
E(\underline{X}) &= \frac{(N+1)\bar{S} - \bar{S}_1}{\bar{S}}\nonumber\\
&= (N+1) - \frac{\bar{S}_1}{\bar{S}}\nonumber\\
&\sim (N+1) - (N - \frac{1}{R-1}) \hspace{0.1in}{\rm by\hspace{0.1in} eq.~(\ref{6.2}})\nonumber\\
\Rightarrow  \lim_{N\rightarrow \infty}E(\underline{X}) &= 1 + \displaystyle{\frac{1}{R-1}} = \displaystyle{\frac{R}{R-1}}\tag{7.3}\label{7.3}
\end{align}</p>

\hfill{$\square$}\\

<p>THEOREM~{\ref{thm-4.4}}:}</p>
<p>\begin{eqnarray*}
\displaystyle{\lim_{N \rightarrow \infty}}E(\underline{X}^2) = 1 + \displaystyle{\frac{3R-1}{(R-1)^2}}
\end{eqnarray*}</p>

<p><em>Proof~:</em></p>

<p>\begin{equation}
Var(\underline{X}) = E(\underline{X}^2) - E(\underline{X})^2\tag{7.4}\label{7.4}
\end{equation}</p>

<p>Using eq.~(\ref{B.14}) we first obtain $E(\underline{X}^2)$.</p>

<p>\begin{align}
E(\underline{X}^2) &= \frac{\bar{S}_2}{\underline{S}} \nonumber\\
&\sim \frac{(N+1)^2\bar{S}}{\bar{S}} - \frac{2(N+1)\bar{S}_1}{\bar{S}} + \frac{\bar{S}_2}{\bar{S}}\nonumber\\
&\sim (N+1)^2 - 2(N+1)E(\bar{X}) +E(\bar{X}^2)\nonumber\\
&\sim (N+1)^2 - 2(N+1)\left(N-\frac{1}{R-1}\right) + \left(\frac{N^2(R-1)^2 - 2N(R-1)+(R+1)}{(R-1)^2}\right)\nonumber\\
&\sim \frac{(R-1)^2 +3R -1}{(R-1)^2}\nonumber
\end{align}</p>

<p>\begin{equation}
\Rightarrow \lim_{N \rightarrow \infty}E(\underline{X}^2) = 1 + \displaystyle{\frac{3R-1}{(R-1)^2}} \tag{7.5}\label{7.5}
\end{equation}</p>

<p>From eq.~(\ref{eq-7.5}) and eq.~(\ref{eq-7.6}), we get</p>
<p>\begin{align}
Var(\underline{X}) &= E(\underline{X}^2) - E(\underline{X})^2\nonumber\\
&\rightarrow 1 + \frac{3R-1}{(R-1)^2} - \frac{R^2}{(R-1)^2}\nonumber\\ 
\Rightarrow \lim_{N \rightarrow \infty}Var(\underline{X}) &= \frac{R}{(R-1)^2}\tag{7.6}\label{7.6}
\end{align}</p>

\hfill{$\square$}\\

<p>Thus, we find that, the limit of the variance of the probability distribution with probability defined by eq.~(\ref{eq-7.1}) to be a simple function $R$, the limit of the ratio of successive elements.</p>
